# ハッカソン展示用 Q&A集

## 想定される質問と回答例

---

## 技術的な質問

### Q1: 角度はどうやって測っているんですか?
**A (簡潔版):**
カメラで手を映すと、GoogleのMediaPipe Handsが手を21個の3D座標点として認識します。その点同士の角度を、ベクトルの内積という数学的手法で計算しています。

**A (詳細版):**
MediaPipe Handsで手のランドマーク21点を検出し、例えば掌屈なら手首と指の付け根4点の座標差からarctan2関数で角度を算出しています。3D座標(X,Y,Z)でベクトル計算し、信頼度スコアで測定品質も評価しています。

**実装コード:** `src/core/infrastructure/mediapipe/angle-calculator.ts`

---

### Q2: MediaPipeって何ですか?
**A:**
Googleが開発したオープンソースの機械学習ライブラリです。カメラ映像から人の手や体を高精度で認識できます。Androidスマホの顔認証などにも使われている技術で、ブラウザでも動作するように最適化されています。

**特徴:**
- リアルタイム処理(30fps以上)
- 軽量(スマホでも動作)
- オープンソース(商用利用可能)

---

### Q3: どのくらいの精度で測れますか?
**A:**
良好な環境(十分な照明、カメラから30-50cm、信頼度0.8以上)で±5度程度の誤差です。

**精度に影響する要因:**
- 照明: 明るいほど高精度
- 距離: カメラから30-50cmが最適
- 手の向き: 正面を向いているほど正確
- 信頼度スコア: 0.8以上なら高精度

実際の測定では信頼度スコアを表示し、低い場合は警告を出しています。

---

### Q4: なぜブラウザで動くんですか?サーバーは?
**A:**
MediaPipeはJavaScriptで書かれていて、ブラウザ上で動作します。WebAssembly技術でネイティブアプリ並みの速度を実現しています。

**サーバー不要の理由:**
- MediaPipeがブラウザで完結
- データはIndexedDB(ブラウザのDB)に保存
- プライバシー保護(データが外部に送信されない)

**使用技術:**
- WebAssembly: C++のコードをブラウザで実行
- WebGL: GPUを使った高速処理
- WebRTC: カメラアクセス

---

### Q5: Z座標(奥行き)はどう測っているんですか?
**A:**
MediaPipe Handsの機械学習モデルが、2Dカメラ映像から3D座標を推定しています。

**推定方法:**
- 手の大きさから距離を推定
- 複数フレームの動きから奥行きを計算
- 学習データ(何千万枚もの手の画像)から統計的に予測

このアプリでは、Z座標は主にベクトルの大きさ計算や信頼度評価に使用しています。掌屈・背屈の角度測定はY座標とX座標をメインに使用しています。

---

### Q6: 信頼度スコアは何ですか?
**A:**
AIの検出がどれだけ確実かを0-1の値で示したものです。

**計算方法:**
```typescript
信頼度 = ベクトルの長さ / 基準値(0.1)
信頼度 = min(1, 信頼度)  // 最大1.0
```

**閾値:**
- 0.8以上: 高信頼度(緑)
- 0.6-0.8: 中信頼度(黄)
- 0.3-0.6: 低信頼度(オレンジ)
- 0.3未満: 測定無効(赤)

低い場合は「手をカメラに近づけてください」などのガイドを表示します。

---

### Q7: なぜ小指側からカメラを配置するんですか?
**A:**
掌屈・背屈の動きが最も見やすい角度だからです。

**他の配置との比較:**
- 正面: 左右の動きは見やすいが、前後が見えない
- 手のひら側: 指が重なって検出しづらい
- **小指側(推奨)**: 前後の動きがY座標の変化として明確に現れる

この配置なら、Y座標の増減だけで掌屈・背屈を判定できます。

---

### Q8: リアルタイムで処理できるのはなぜ?
**A:**
MediaPipe Handsが軽量に設計されているからです。

**最適化の工夫:**
- モデルの軽量化(MobileNet使用)
- 手の検出と追跡を分離(追跡は軽い処理)
- WebAssembly/WebGLによる高速化
- 不要な計算を省略(手が検出されないフレームはスキップ)

**処理速度:**
- 手の検出: 10-30ms/フレーム
- 角度計算: 1-5ms/フレーム
- 合計: 30fps以上で動作可能

---

## アプリケーション全般の質問

### Q9: どんな人が使うことを想定していますか?
**A:**
手首のリハビリが必要な方や、理学療法士・作業療法士の先生方を想定しています。

**ユースケース:**
- 自宅でのリハビリ記録
- 病院での初期評価
- 可動域の経過観察
- リハビリのモチベーション維持

---

### Q10: データはどこに保存されますか?
**A:**
ブラウザのIndexedDBに保存されます。サーバーには一切送信されません。

**保存内容:**
- 測定日時
- 各方向の角度
- 信頼度スコア
- メモ(任意)

**プライバシー:**
- ローカル保存のみ(外部送信なし)
- カメラ映像も保存されない
- 個人情報は不要

---

### Q11: オフラインでも使えますか?
**A:**
はい、PWA(Progressive Web App)として動作します。

**初回アクセス時:**
1. MediaPipeのモデルをダウンロード(約5MB)
2. アプリのファイルをキャッシュ

**2回目以降:**
- オフラインで起動
- カメラさえあれば測定可能

**インストール:**
ブラウザで「ホーム画面に追加」するとアプリのように使えます。

---

### Q12: スマホでも使えますか?
**A:**
はい、レスポンシブデザインで対応しています。

**推奨環境:**
- Android: Chrome 90以上
- iOS: Safari 14以上
- タブレット推奨(画面が大きい方が使いやすい)

**注意点:**
- スマホを固定する必要あり(手で持つと両手が使えない)
- PCの方がカメラ位置を調整しやすい

---

### Q13: 医療機器として使えますか?
**A:**
いいえ、医療機器認証を受けていません。

**位置づけ:**
- 教育・参考目的
- セルフモニタリングツール
- リハビリの補助

**医療機器との違い:**
- 診断には使用不可
- 治療計画の根拠にできない
- あくまで参考値

正式な診断・治療には必ず医療機関を受診してください。

---

## 開発に関する質問

### Q14: どんな技術スタックですか?
**A:**
```
フロントエンド: Next.js 14 + TypeScript
状態管理: Jotai
AI/ML: MediaPipe Hands & Pose
データベース: Dexie.js (IndexedDB)
グラフ: Recharts
スタイル: Sass
```

**アーキテクチャ:**
クリーンアーキテクチャを採用し、ビジネスロジックとUIを分離しています。

---

### Q15: なぜNext.jsを選んだんですか?
**A:**
PWA対応、SSG/SSR、TypeScript統合など、必要な機能が揃っているからです。

**選定理由:**
- PWA対応が簡単
- ファイルベースルーティング
- TypeScriptの完全サポート
- ビルドの最適化
- 開発体験が良い

---

### Q16: クリーンアーキテクチャを採用した理由は?
**A:**
将来的な拡張性とテストのしやすさを重視したためです。

**メリット:**
- ビジネスロジックが独立(UIに依存しない)
- テストしやすい
- 他のライブラリへの移行が容易
- チームでの開発がしやすい

**構成:**
```
domain: ビジネスルール・型定義
application: ユースケース
infrastructure: 外部ライブラリ
lib: ヘルパー関数
components: UI
```

---

### Q17: 開発期間はどのくらい?
**A (正直に答える場合):**
企画から実装まで約○週間です。

**内訳:**
- 企画・調査: ○日
- MediaPipe学習: ○日
- 角度計算実装: ○日
- UI実装: ○日
- テスト・調整: ○日

---

### Q18: 一番苦労したところは?
**A (技術的課題):**
角度計算のアルゴリズム選定です。最初は2D平面での計算でしたが、精度が低く、3D座標と外積を使う方式に変更しました。

**その他の課題:**
- カメラ位置の最適化
- 信頼度スコアの閾値調整
- リアルタイム処理とバッテリー消費のバランス

---

### Q19: 他の類似アプリとの違いは?
**A:**
ブラウザで完結し、インストール不要な点です。

**差別化ポイント:**
- サーバー不要(プライバシー保護)
- 特別な機器不要(カメラのみ)
- オフライン動作
- オープンソース技術

**既存ソリューションとの比較:**
- 医療機器: 高精度だが高価・大型
- スマホアプリ: インストール必要、ストア審査
- 当アプリ: URLアクセスだけで即使用可能

---

### Q20: 今後の展開は?
**A:**
以下の機能を検討しています:

**短期:**
- 他の関節対応(肘、肩、膝など)
- データエクスポート機能(CSV, PDF)
- 目標設定とリマインダー

**中期:**
- 理学療法士向けの管理画面
- 複数患者のデータ管理
- AIによる改善アドバイス

**長期:**
- 医療機器認証の取得
- 病院・クリニックへの導入
- リハビリプログラムの自動生成

---

## デモ時のトラブルシューティング

### Q21: カメラが映らない場合は?
**A:**
1. ブラウザのカメラ許可を確認
2. 他のアプリがカメラを使用していないか確認
3. ページをリロード
4. 別のブラウザで試す

---

### Q22: 角度が正しく表示されない場合は?
**A:**
1. 手がカメラの中央にあるか確認
2. 照明を明るくする
3. カメラとの距離を調整(30-50cm)
4. 信頼度スコアを確認(0.8以上が理想)

---

### Q23: 動作が重い場合は?
**A:**
1. 他のタブ・アプリを閉じる
2. ブラウザを再起動
3. カメラ解像度を下げる設定を追加(今後の改善点)

---

## その他

### Q24: ソースコードは公開していますか?
**A (公開する場合):**
はい、GitHubで公開予定です。MITライセンスでオープンソース化します。

**A (公開しない場合):**
現時点では公開していませんが、技術的な質問には可能な範囲でお答えします。

---

### Q25: 商用利用は考えていますか?
**A:**
現在は検討中です。医療機器認証を取得すれば、病院やクリニックへの導入も視野に入れています。

**収益モデル候補:**
- 病院向けライセンス販売
- 理学療法士向けSaaS
- データ分析サービス

---

## 展示時の推奨応答フロー

1. **最初の質問に対して:**
   - 簡潔版で答える(30秒以内)
   - 相手の反応を見る

2. **興味を示したら:**
   - 詳細版で説明
   - 実際に画面を見せる

3. **技術的質問が来たら:**
   - このQ&Aを参照
   - 必要ならコードを見せる

4. **わからない質問は:**
   - 正直に「調べて後日回答します」
   - 連絡先を交換

---

**このQ&Aは随時更新してください。**
**実際に聞かれた質問を追加していくと、より実用的になります。**
